{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh\n"
      ],
      "metadata": {
        "id": "924KWUpyby8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e4ff8e-3f1f-4026-adc8-72da404d37f7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve > /dev/null 2>&1 &"
      ],
      "metadata": {
        "id": "xSMocEbvIGVV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull llama3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woBLHXQ_Se1H",
        "outputId": "43da677b-bc5c-4ac0-8e81-3a300c53e823"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textgrid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XsSy3qXMVRa",
        "outputId": "2c8ecede-f5c4-44d3-b956-2880f4dfecf3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textgrid\n",
            "  Downloading TextGrid-1.6.1.tar.gz (9.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: textgrid\n",
            "  Building wheel for textgrid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textgrid: filename=TextGrid-1.6.1-py3-none-any.whl size=10146 sha256=09b5010d9a11ffd3e61f4ebf872582e87bc3f3675f48ccf307dbb5a0c70a3678\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/86/7b/5766bd19fa4b4554667dd186e614b5a438ab14eec9c5a3642a\n",
            "Successfully built textgrid\n",
            "Installing collected packages: textgrid\n",
            "Successfully installed textgrid-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from textgrid import TextGrid\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "# âœ… HF CLIP (unchanged)\n",
        "from transformers import CLIPTokenizer, CLIPTextModel\n",
        "\n",
        "# âœ… Use separate device flags\n",
        "compute_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "clip_device = torch.device(\"cpu\")  # âœ… Force CLIP to stay on CPU\n",
        "\n",
        "\n",
        "class FMRIDataset():\n",
        "    def __init__(self, fmri_path, textgrid_path, TR=1.5):\n",
        "        self.clip_tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "        self.clip_model = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\", use_safetensors=True).to(\"cpu\")\n",
        "        self.TR = TR\n",
        "        self.fmri = self._load_fmri(fmri_path)\n",
        "        self.trans_df = self._load_transcript(textgrid_path)\n",
        "        self.pairs = self._align_fmri_with_text()\n",
        "        self.X, self.y = self._embed_pairs()\n",
        "        self.train_loader, self.test_loader = self.get_dataloaders()\n",
        "\n",
        "    def _load_fmri(self, path):\n",
        "        with h5py.File(path, \"r\") as f:\n",
        "            data = f[\"data\"][:]\n",
        "        # print(\"fMRI shape:\", data.shape)\n",
        "        return data\n",
        "\n",
        "    def _load_transcript(self, path):\n",
        "        tg = TextGrid.fromFile(path)\n",
        "        word_tier = next((tier for tier in tg.tiers if \"word\" in tier.name.lower()), None)\n",
        "\n",
        "        if word_tier is None:\n",
        "            raise ValueError(\"No 'word' tier found in TextGrid.\")\n",
        "\n",
        "        transcript = [\n",
        "            {\n",
        "                \"word\": interval.mark.strip(),\n",
        "                \"start\": interval.minTime,\n",
        "                \"end\": interval.maxTime\n",
        "            }\n",
        "            for interval in word_tier.intervals\n",
        "            if interval.mark and interval.mark.strip().lower() not in [\"\", \"sp\", \"sil\", \"<unk>\"]\n",
        "        ]\n",
        "\n",
        "        return pd.DataFrame(transcript)\n",
        "\n",
        "    def _align_fmri_with_text(self):\n",
        "        pairs = []\n",
        "        n_TRs = self.fmri.shape[0]\n",
        "\n",
        "        for t_idx in range(n_TRs):\n",
        "            t_start = t_idx * self.TR\n",
        "            t_end = t_start + self.TR\n",
        "\n",
        "            words_in_tr = self.trans_df[\n",
        "                            (self.trans_df['end'] > t_start) &\n",
        "                            (self.trans_df['start'] < t_end)\n",
        "                        ]\n",
        "\n",
        "            if not words_in_tr.empty:\n",
        "                sentence = \" \".join(words_in_tr['word'].tolist())\n",
        "                brain_vec = self.fmri[t_idx]\n",
        "                pairs.append((brain_vec, sentence))\n",
        "\n",
        "        # print(f\"Total aligned (brain, sentence) pairs: {len(pairs)}\")\n",
        "        return pairs\n",
        "\n",
        "    def _embed_pairs(self):\n",
        "        X = []\n",
        "        sentences = []\n",
        "\n",
        "        for brain_vec, sentence in self.pairs:\n",
        "            X.append(brain_vec)\n",
        "            sentences.append(sentence)\n",
        "\n",
        "        self.sentences = sentences\n",
        "        X = np.array(X, dtype=np.float32)\n",
        "        # print(\"Unique sentences:\", len(set(sentences)))\n",
        "        # print(\"Sample sentences:\", list(set(sentences))[:5])\n",
        "\n",
        "        # Recompute CLIP embeddings for current dataset\n",
        "        inputs = self.clip_tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True).to(clip_device)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.clip_model(**inputs)\n",
        "            y = outputs.pooler_output.cpu().numpy().astype(np.float32)\n",
        "\n",
        "        y = y / np.linalg.norm(y, axis=1, keepdims=True)  # Normalize\n",
        "\n",
        "        # âœ… Debug: ensure target vectors vary\n",
        "        # print(\"Target embed shape:\", y.shape)\n",
        "        # print(\"Example embed norm:\", np.linalg.norm(y[0]))\n",
        "        # print(\"Unique target vectors:\", len(np.unique(y, axis=0)))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "    def get_dataloaders(self, batch_size=32, test_size=0.2, shuffle=True):\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test, self.train_sentences, self.test_sentences = train_test_split(\n",
        "            self.X, self.y, self.sentences, test_size=test_size, shuffle=False\n",
        "        )\n",
        "\n",
        "        train_dataset = TensorDataset(torch.from_numpy(self.X_train), torch.from_numpy(self.y_train))\n",
        "        test_dataset = TensorDataset(torch.from_numpy(self.X_test), torch.from_numpy(self.y_test))\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "        return train_loader, test_loader\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]), torch.from_numpy(self.y[idx])\n"
      ],
      "metadata": {
        "id": "o9eJ4_fOMK4M"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXemHG55MrE9",
        "outputId": "60555bb4-9db3-4bdf-da25-854e62b19de0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fmri_path = '/content/drive/MyDrive/dataset/quietfire.hf5'\n",
        "textgrid_path = '/content/drive/MyDrive/dataset/quietfire.TextGrid'"
      ],
      "metadata": {
        "id": "zn15Xh_TMdbC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = FMRIDataset(fmri_path=fmri_path, textgrid_path=textgrid_path)"
      ],
      "metadata": {
        "id": "skHmuW-uIsEM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import h5py\n",
        "\n",
        "class SpatialFMRI2Embedding(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "\n",
        "            nn.Linear(1024, output_dim),\n",
        "            nn.LayerNorm(output_dim)\n",
        "        )\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
        "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=10)\n",
        "        self.dataset_path = \"/content/drive/MyDrive/dataset/\"\n",
        "\n",
        "        self.dataset_paths = self.prepare_file_list(self.dataset_path)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def clip_contrastive_loss(self, pred, target, temperature=0.07):\n",
        "        # pred, target: (B, D), both normalized\n",
        "        logits = torch.matmul(pred, target.T) / temperature  # shape (B, B)\n",
        "        labels = torch.arange(len(pred)).to(pred.device)     # shape (B,)\n",
        "\n",
        "        # CrossEntropy between each row and its true label\n",
        "        loss_i = F.cross_entropy(logits, labels)\n",
        "        loss_t = F.cross_entropy(logits.T, labels)\n",
        "        return (loss_i + loss_t) / 2\n",
        "\n",
        "    def prepare_file_list(self, dataset_dir):\n",
        "        # List all files\n",
        "        all_files = os.listdir(dataset_dir)\n",
        "\n",
        "        # Group files by base name\n",
        "        file_pairs = []\n",
        "        base_names = set(f.split('.')[0] for f in all_files)\n",
        "\n",
        "        for name in base_names:\n",
        "            h5f_path = os.path.join(dataset_dir, f\"{name}.hf5\")\n",
        "            tg_path = os.path.join(dataset_dir, f\"{name}.TextGrid\")\n",
        "\n",
        "            if os.path.exists(h5f_path) and os.path.exists(tg_path):\n",
        "                try:\n",
        "                    with h5py.File(h5f_path, 'r') as f:\n",
        "                        data = f['data'][:]  # Change 'data' if your key is different\n",
        "                        if np.isnan(data).any() or np.isinf(data).any():\n",
        "                            print(f\"âŒ Skipping {name} due to NaNs/Infs in {h5f_path}\")\n",
        "                            continue\n",
        "                except Exception as e:\n",
        "                    print(f\"âš ï¸ Error loading {h5f_path}: {e}\")\n",
        "                    continue\n",
        "\n",
        "                file_pairs.append([h5f_path, tg_path])\n",
        "\n",
        "        # Print selected valid pairs\n",
        "        for h5f, tg in file_pairs:\n",
        "            print(f\"âœ… H5F: {h5f}  |  TextGrid: {tg}\")\n",
        "\n",
        "        return file_pairs"
      ],
      "metadata": {
        "id": "XZteR5_quEnn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SpatialFMRI2Embedding(dataset.X.shape[1], dataset.y.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK4TBImYwqWF",
        "outputId": "a617c14b-0412-4902-9ccc-72ba11358f11"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… H5F: /content/drive/MyDrive/dataset/quietfire.hf5  |  TextGrid: /content/drive/MyDrive/dataset/quietfire.TextGrid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/spatial_mlp_model.pth', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "0pjAlAnzVkQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f10d702f-152b-4879-ea1e-2572a5cc2ed9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_top_k_similar(pred_vec, all_gt_vecs, all_gt_sentences, k=3):\n",
        "    sims = cosine_similarity(pred_vec.reshape(1, -1), all_gt_vecs)[0]\n",
        "    top_k = sims.argsort()[-k:][::-1]\n",
        "    return [(all_gt_sentences[i], sims[i]) for i in top_k]\n",
        "\n",
        "model.eval()\n",
        "sample_vecs = []\n",
        "pred_sentences = []\n",
        "ground_truths = []\n",
        "for i in range(20, 30):\n",
        "  sample_vec = torch.from_numpy(dataset.X_test[i]).unsqueeze(0)\n",
        "  sample_vecs.append(sample_vec)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      pred_embed = model(sample_vec).cpu().numpy()\n",
        "\n",
        "  sims = cosine_similarity(pred_embed, dataset.y_test)  # âœ… Compare only to test embeddings\n",
        "  best_idx = np.argmax(sims)\n",
        "\n",
        "  print(\"\\nðŸ§  Predicted sentence:\")\n",
        "  print(dataset.test_sentences[best_idx])  # âœ… Correct retrieval\n",
        "  pred_sentences.append(dataset.test_sentences[best_idx])\n",
        "\n",
        "  print(\"\\nðŸŽ¯ Ground truth:\")\n",
        "  print(dataset.test_sentences[i])\n",
        "  ground_truths.append(dataset.test_sentences[i])\n",
        "\n",
        "  # SpatialFMRI2Embedding\n",
        "  top_preds = get_top_k_similar(pred_embed, dataset.y_test, dataset.test_sentences)\n",
        "  for sent, score in top_preds:\n",
        "      print(f\"{score:.3f} | {sent}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7lOfe1dwJ8H",
        "outputId": "d30f6d1a-7ce4-416b-9a6d-32f212ec525a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§  Predicted sentence:\n",
            "{LG}\n",
            "\n",
            "ðŸŽ¯ Ground truth:\n",
            "HE CAME TOWARDS ME\n",
            "0.167 | {LG}\n",
            "0.103 | HAND IT'S\n",
            "0.096 | {NS} I SPRAYED\n",
            "\n",
            "ðŸ§  Predicted sentence:\n",
            "{LG} AND THIS ONE\n",
            "\n",
            "ðŸŽ¯ Ground truth:\n",
            "AND AS HE GOT CLOSER\n",
            "0.154 | {LG} AND THIS ONE\n",
            "0.148 | {LG} AND THEN HE BEGAN\n",
            "0.146 | AND THIS HULKING GOLIATH\n",
            "\n",
            "ðŸ§  Predicted sentence:\n",
            "AND THIS HULKING GOLIATH\n",
            "\n",
            "ðŸŽ¯ Ground truth:\n",
            "CLOSER HIS EYES NARROWED\n",
            "0.140 | AND THIS HULKING GOLIATH\n",
            "0.090 | {NS} I SPRAYED\n",
            "0.088 | {LG} AND THIS ONE\n",
            "\n",
            "ðŸ§  Predicted sentence:\n",
            "STAGGERING TOWARDS THE STREET\n",
            "\n",
            "ðŸŽ¯ Ground truth:\n",
            "NARROWED AND I COULDN'T\n",
            "0.144 | STAGGERING TOWARDS THE STREET\n",
            "0.122 | LUMBERED TOWARDS IT\n",
            "0.119 | SIZE OF THE OTHER ONE AND\n",
            "\n",
            "ðŸ§  Predicted sentence:\n",
            "HUMAN ARENA AND\n",
            "\n",
            "ðŸŽ¯ Ground truth:\n",
            "COULDN'T TELL WHETHER IT WAS BECAUSE\n",
            "0.132 | HUMAN ARENA AND\n",
            "0.104 | SIZE OF THE OTHER ONE AND\n",
            "0.103 | MIME'S LUNCHTIME MENU\n",
            "\n",
            "ðŸ§  Predicted sentence:\n",
            "AND THIS HULKING GOLIATH\n",
            "\n",
            "ðŸŽ¯ Ground truth:\n",
            "BECAUSE OF HIS RECOGNIZING\n",
            "0.141 | AND THIS HULKING GOLIATH\n",
            "0.127 | HIS {NS} EYES {NS} GOT WILD\n",
            "0.120 | HAND IT'S\n",
            "\n",
            "ðŸ§  Predicted sentence:\n",
            "OR WHETHER HE WAS STRATEGIZING\n",
            "\n",
            "ðŸŽ¯ Ground truth:\n",
            "RECOGNIZING ME FROM BEFORE\n",
            "0.159 | OR WHETHER HE WAS STRATEGIZING\n",
            "0.151 | AWAY I LIFTED MY\n",
            "0.146 | WAS TO PLAY DIRTY\n",
            "\n",
            "ðŸ§  Predicted sentence:\n",
            "GLOWERING AT ME LIKE HE\n",
            "\n",
            "ðŸŽ¯ Ground truth:\n",
            "BEFORE FROM WHAT HE HAD\n",
            "0.148 | GLOWERING AT ME LIKE HE\n",
            "0.139 | AND THIS HULKING GOLIATH\n",
            "0.137 | SIZE OF THE OTHER ONE AND\n",
            "\n",
            "ðŸ§  Predicted sentence:\n",
            "SPRAY AND I SPRAYED HIM IN HIS\n",
            "\n",
            "ðŸŽ¯ Ground truth:\n",
            "HAD DONE TO ME OR\n",
            "0.175 | SPRAY AND I SPRAYED HIM IN HIS\n",
            "0.173 | BACK AND I SPRAYED HIM\n",
            "0.139 | {LG} AND THEN HE BEGAN\n",
            "\n",
            "ðŸ§  Predicted sentence:\n",
            "SPRAY AND I SPRAYED HIM IN HIS\n",
            "\n",
            "ðŸŽ¯ Ground truth:\n",
            "OR WHETHER HE WAS STRATEGIZING\n",
            "0.117 | SPRAY AND I SPRAYED HIM IN HIS\n",
            "0.109 | BACK AND I SPRAYED HIM\n",
            "0.097 | KARATE CHOPPED MY RIGHT HAND\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred_sentences)\n",
        "print(ground_truths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp7rQ3aJOhf6",
        "outputId": "0983ecdf-14d4-4edc-ca89-b648874c3a08"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['{LG}', '{LG} AND THIS ONE', 'AND THIS HULKING GOLIATH', 'STAGGERING TOWARDS THE STREET', 'HUMAN ARENA AND', 'AND THIS HULKING GOLIATH', 'OR WHETHER HE WAS STRATEGIZING', 'GLOWERING AT ME LIKE HE', 'SPRAY AND I SPRAYED HIM IN HIS', 'SPRAY AND I SPRAYED HIM IN HIS']\n",
            "['HE CAME TOWARDS ME', 'AND AS HE GOT CLOSER', 'CLOSER HIS EYES NARROWED', \"NARROWED AND I COULDN'T\", \"COULDN'T TELL WHETHER IT WAS BECAUSE\", 'BECAUSE OF HIS RECOGNIZING', 'RECOGNIZING ME FROM BEFORE', 'BEFORE FROM WHAT HE HAD', 'HAD DONE TO ME OR', 'OR WHETHER HE WAS STRATEGIZING']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json\n",
        "\n",
        "predicted_story = ' '.join(pred_sentences)\n",
        "ground_truth = ' '.join(ground_truths)\n",
        "\n",
        "# Step 3: Send to TinyLlama (Ollama API)\n",
        "url = \"http://localhost:11434/api/generate\"\n",
        "payload = {\n",
        "    \"model\": \"llama3\",\n",
        "    \"prompt\": f\"Below is a predicted story from fMRI signals by a model. They tend to have noise, so sentences might not make complete sense independently. Do your best to summarize the given below text into sentences that makes sense and flow naturally. The total length of the text should be approximately similar to the input. This is the Story: {predicted_story}\"\n",
        "}\n",
        "\n",
        "resp = requests.post(url, json=payload, stream=True)\n",
        "\n",
        "output_text = \"\"\n",
        "for line in resp.iter_lines():\n",
        "    if line:\n",
        "        output_text += json.loads(line)[\"response\"]\n",
        "\n",
        "print(\"ðŸ§  Predicted sentence:\", output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE8J8esuyLxO",
        "outputId": "870044d2-f2df-483d-d780-8acf87c0f35c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  Predicted sentence: Here's a summarized version of the text:\n",
            "\n",
            "A massive stag was staggering towards the street, its human observers watching with great interest. This hulking goliath had the attention of everyone around, as if it was strategizing its next move. Meanwhile, I was fixated on it, my eyes locked in a staring contest with the creature's piercing gaze. Just as suddenly, I reacted and sprayed something at the stag, which in turn sprayed me back. The exchange seemed to be escalating rapidly, leaving everyone around us in awe of the spectacle unfolding before their eyes.\n",
            "\n",
            "Please note that this summary is just one possible interpretation of the original text, as fMRI signal-based stories can be open to multiple interpretations due to the inherent noise and ambiguity in the data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "payload = {\n",
        "    \"model\": \"llama3\",\n",
        "    \"prompt\": f\"Below is a ground truth stroy. Do your best to convert the given below text into sentences that makes sense and flow naturally. The total length of the text should be approximately similar to the input. This is the Story: {ground_truth}\"\n",
        "}\n",
        "\n",
        "resp = requests.post(url, json=payload, stream=True)\n",
        "\n",
        "output_text = \"\"\n",
        "for line in resp.iter_lines():\n",
        "    if line:\n",
        "        output_text += json.loads(line)[\"response\"]\n",
        "\n",
        "print(\"ðŸ§  Ground truth:\", output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emA-ggeFQQfL",
        "outputId": "81e241cb-646f-46f6-8594-bd9f902977b4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  Ground truth: Here is the rewritten text in a natural flowing format:\n",
            "\n",
            "As he approached me, his eyes narrowed and I couldn't help but wonder if it was because he had recognized me from before. Had he seen what he had done to me, or was he simply strategizing something?\n",
            "\n",
            "The original text has 32 words, and my rewritten version has 36 words, so they are approximately the same length. Let me know if you have any further requests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BdRHqhOmRkZ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}